{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a7096a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01ecd447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8ef09b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvMixer(dim, depth, kernel_size=5, patch_size=2, n_classes=10):\n",
    "    \n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm2d(dim),\n",
    "        *[nn.Sequential(\n",
    "            Residual(nn.Sequential(\n",
    "                nn.Conv2d(dim, dim, kernel_size, groups=dim, padding='same'),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "            )),\n",
    "            nn.Conv2d(dim, dim, kernel_size=1),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm2d(dim)\n",
    "        )for i in range(depth)],\n",
    "        nn.AdaptiveAvgPool2d((1,1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(dim, n_classes)\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e2cf10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar10_std = (0.2471, 0.2435, 0.2616)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32, scale=(0.75, 1.0), ratio=(1.0, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandAugment(num_ops=1, magnitude=8),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std),\n",
    "    transforms.RandomErasing(p=0.25)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
    "])\n",
    "\n",
    "epochs = 25\n",
    "batch_size =512\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7f9ad20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# check cuda and device\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "if cuda:\n",
    "    print(torch.cuda.get_device_name())\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae67b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = lambda t: np.interp([t], [0, epochs*2//5, epochs*4//5, epochs], \n",
    "                                  [0, 0.01, 0.01/20.0, 0])[0]\n",
    "\n",
    "depth = 10\n",
    "hdim = 256\n",
    "psize = 2\n",
    "conv_ks = 5\n",
    "clip_norm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33f012d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvMixer(hdim, depth, patch_size=psize, kernel_size=conv_ks, n_classes=10)\n",
    "model = nn.DataParallel(model, device_ids=[0]).cuda()\n",
    "\n",
    "opt = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8741f976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvMixer: Epoch: 0 | Train Acc: 0.3489, Test Acc: 0.4903, Time: 38.6, lr: 0.001000\n",
      "ConvMixer: Epoch: 1 | Train Acc: 0.5484, Test Acc: 0.5826, Time: 31.4, lr: 0.002000\n",
      "ConvMixer: Epoch: 2 | Train Acc: 0.6435, Test Acc: 0.6497, Time: 31.5, lr: 0.003000\n",
      "ConvMixer: Epoch: 3 | Train Acc: 0.7012, Test Acc: 0.7146, Time: 31.3, lr: 0.004000\n",
      "ConvMixer: Epoch: 4 | Train Acc: 0.7353, Test Acc: 0.7432, Time: 31.3, lr: 0.005000\n",
      "ConvMixer: Epoch: 5 | Train Acc: 0.7596, Test Acc: 0.7901, Time: 31.4, lr: 0.006000\n",
      "ConvMixer: Epoch: 6 | Train Acc: 0.7776, Test Acc: 0.8177, Time: 31.4, lr: 0.007000\n",
      "ConvMixer: Epoch: 7 | Train Acc: 0.7911, Test Acc: 0.7975, Time: 31.4, lr: 0.008000\n",
      "ConvMixer: Epoch: 8 | Train Acc: 0.8059, Test Acc: 0.8186, Time: 31.6, lr: 0.009000\n",
      "ConvMixer: Epoch: 9 | Train Acc: 0.8150, Test Acc: 0.8346, Time: 31.5, lr: 0.010000\n",
      "ConvMixer: Epoch: 10 | Train Acc: 0.8249, Test Acc: 0.8293, Time: 31.6, lr: 0.009050\n",
      "ConvMixer: Epoch: 11 | Train Acc: 0.8423, Test Acc: 0.8596, Time: 31.8, lr: 0.008100\n",
      "ConvMixer: Epoch: 12 | Train Acc: 0.8580, Test Acc: 0.8638, Time: 31.7, lr: 0.007150\n",
      "ConvMixer: Epoch: 13 | Train Acc: 0.8706, Test Acc: 0.8823, Time: 31.7, lr: 0.006200\n",
      "ConvMixer: Epoch: 14 | Train Acc: 0.8806, Test Acc: 0.8854, Time: 31.7, lr: 0.005250\n",
      "ConvMixer: Epoch: 15 | Train Acc: 0.8895, Test Acc: 0.8895, Time: 31.8, lr: 0.004300\n",
      "ConvMixer: Epoch: 16 | Train Acc: 0.9025, Test Acc: 0.9010, Time: 31.8, lr: 0.003350\n",
      "ConvMixer: Epoch: 17 | Train Acc: 0.9125, Test Acc: 0.9027, Time: 32.0, lr: 0.002400\n",
      "ConvMixer: Epoch: 18 | Train Acc: 0.9226, Test Acc: 0.9085, Time: 31.7, lr: 0.001450\n",
      "ConvMixer: Epoch: 19 | Train Acc: 0.9312, Test Acc: 0.9129, Time: 31.7, lr: 0.000500\n",
      "ConvMixer: Epoch: 20 | Train Acc: 0.9345, Test Acc: 0.9153, Time: 31.8, lr: 0.000400\n",
      "ConvMixer: Epoch: 21 | Train Acc: 0.9369, Test Acc: 0.9155, Time: 31.7, lr: 0.000300\n",
      "ConvMixer: Epoch: 22 | Train Acc: 0.9401, Test Acc: 0.9153, Time: 31.6, lr: 0.000200\n",
      "ConvMixer: Epoch: 23 | Train Acc: 0.9409, Test Acc: 0.9167, Time: 31.7, lr: 0.000100\n",
      "ConvMixer: Epoch: 24 | Train Acc: 0.9402, Test Acc: 0.9166, Time: 31.6, lr: 0.000000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_loss, train_acc, n = 0, 0, 0\n",
    "    for i, (X, y) in enumerate(trainloader):\n",
    "        model.train()\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "\n",
    "        lr = lr_schedule(epoch + (i + 1)/len(trainloader))\n",
    "        opt.param_groups[0].update(lr=lr)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(X)\n",
    "            loss = criterion(output, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        if clip_norm:\n",
    "            scaler.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item() * y.size(0)\n",
    "        train_acc += (output.max(1)[1] == y).sum().item()\n",
    "        n += y.size(0)\n",
    "        \n",
    "    model.eval()\n",
    "    test_acc, m = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(testloader):\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(X)\n",
    "            test_acc += (output.max(1)[1] == y).sum().item()\n",
    "            m += y.size(0)\n",
    "\n",
    "    print(f'ConvMixer: Epoch: {epoch} | Train Acc: {train_acc/n:.4f}, Test Acc: {test_acc/m:.4f}, Time: {time.time() - start:.1f}, lr: {lr:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3d8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043ffad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
